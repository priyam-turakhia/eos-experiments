{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb613d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.nn.utils import parameters_to_vector\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import LinearOperator, eigsh\n",
    "from typing import List\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57d34c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hvp(network: nn.Module, loss_fn: nn.Module, loader: DataLoader, vector: torch.Tensor):\n",
    "    \n",
    "    device = vector.device\n",
    "    \n",
    "    p = len(parameters_to_vector(network.parameters()))\n",
    "    hvp = torch.zeros(p, device = device)\n",
    "    \n",
    "    for data, target in loader:\n",
    "\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        preds = network(data)\n",
    "\n",
    "        if isinstance(loss_fn, nn.MSELoss):\n",
    "            target_tensor = F.one_hot(target, num_classes=preds.size(1)).float().to(device)\n",
    "        else:\n",
    "            target_tensor = target\n",
    "\n",
    "        loss = loss_fn(preds, target_tensor) / len(loader.dataset)\n",
    "        grads = torch.autograd.grad(loss, network.parameters(), create_graph = True)\n",
    "        dot = parameters_to_vector(grads).mul(vector).sum()\n",
    "        grads2 = torch.autograd.grad(dot, network.parameters(), retain_graph = True)\n",
    "        hvp += parameters_to_vector(grads2)\n",
    "        \n",
    "    return hvp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b4f221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lanczos(matrix_vector, dim: int, neigs: int, device: torch.device):\n",
    "    \n",
    "    def mv(x):\n",
    "        v = torch.tensor(x, dtype = torch.float, device = device)\n",
    "        hv = matrix_vector(v)\n",
    "        return hv.to('cpu').numpy()\n",
    "    \n",
    "    op = LinearOperator((dim, dim), matvec = mv)\n",
    "    evals, _ = eigsh(op, k = neigs)\n",
    "    sorted_evals = np.sort(evals)[::-1].copy()\n",
    "    return torch.from_numpy(sorted_evals).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f762cdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNN(nn.Module):\n",
    "\n",
    "    def __init__(self, activation: str, hidden_sizes: List[int]):\n",
    "\n",
    "        super().__init__()\n",
    "        act = {'relu': nn.ReLU(), 'tanh': nn.Tanh(), 'sigmoid': nn.Sigmoid()}[activation]\n",
    "        layers: List[nn.Module] = [nn.Flatten()]\n",
    "        in_size = 28 * 28\n",
    "        \n",
    "        for hs in hidden_sizes:\n",
    "            layers.append(nn.Linear(in_size, hs))\n",
    "            layers.append(act)\n",
    "            in_size = hs\n",
    "            \n",
    "        layers.append(nn.Linear(in_size, 10))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93463e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_visuals(\n",
    "    iterations: int,\n",
    "    losses: List[float],\n",
    "    accs: List[float],\n",
    "    traj_lengths: List[float],\n",
    "    eigs: List[List[float]],\n",
    "    cumulative_changes: Dict[str, float],\n",
    "    learning_rate: float,\n",
    "    hessian_k: int\n",
    "):\n",
    "    iters = list(range(1, iterations + 1))\n",
    "    \n",
    "    min_loss, max_loss = min(losses), max(losses)\n",
    "    padding = 0.1 * (max_loss - min_loss)\n",
    "    plt.figure()\n",
    "    plt.plot(iters, losses)\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim(min_loss - padding, max_loss + padding)\n",
    "    plt.title('Training Loss')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(iters, accs)\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title('Training Accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    cum_dist = np.cumsum(traj_lengths) \n",
    "    plt.figure()\n",
    "    plt.plot(iters, cum_dist)\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Cumulative Distance')\n",
    "    plt.title('Cumulative Optimization Trajectory Length')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    for i in range(hessian_k):\n",
    "        xs, ys = [], []\n",
    "        for epoch, row in enumerate(eigs, start=1):\n",
    "            val = row[i]\n",
    "            if val is not None:\n",
    "                xs.append(epoch)\n",
    "                ys.append(val)\n",
    "        plt.plot(xs, ys, label=f'λ_{i+1}')\n",
    "    plt.axhline(2/learning_rate, linestyle=':', label='2/η')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Eigenvalue')\n",
    "    plt.title('Top Hessian Eigenvalues')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    top = sorted(cumulative_changes.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    names, vals = zip(*top)\n",
    "    plt.figure()\n",
    "    plt.barh(names, vals)\n",
    "    plt.xlabel('Cumulative Parameter Change Norm')\n",
    "    plt.title('Top 5 Principal Parameters')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    print('Top 5 parameters by cumulative change:', names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce20f4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    subset_size: int,\n",
    "    seed_data: int,\n",
    "    seed_params: int,\n",
    "    hidden_sizes: List[int],\n",
    "    activation: str,\n",
    "    loss_fn: str,\n",
    "    learning_rate: float,\n",
    "    iterations: int,\n",
    "    hessian_freq: int,\n",
    "    hessian_k: int\n",
    "):\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    initial_state = torch.get_rng_state()\n",
    "\n",
    "    torch.manual_seed(seed_data)\n",
    "    full_train = datasets.MNIST(root = './data', train = True, download = True, transform = transforms.ToTensor())\n",
    "    subset = Subset(full_train, torch.randperm(len(full_train))[:subset_size].tolist())\n",
    "    loader = DataLoader(subset, batch_size = len(subset), shuffle = False)\n",
    "\n",
    "    torch.set_rng_state(initial_state)\n",
    "    torch.manual_seed(seed_params)\n",
    "\n",
    "    model = FCNN(activation, hidden_sizes).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "    criterion = {'cross_entropy': nn.CrossEntropyLoss(), 'mse': nn.MSELoss()}[loss_fn]\n",
    "    criterion_sum = {'cross_entropy': nn.CrossEntropyLoss(reduction = 'sum'), 'mse': nn.MSELoss(reduction = 'sum')}[loss_fn]\n",
    "\n",
    "    prev_params = parameters_to_vector(model.parameters()).detach().clone().to(device)\n",
    "    prev_param_dict = {name: param.clone().detach() for name, param in model.named_parameters()}\n",
    "    cumulative_changes = {name: 0.0 for name, _ in model.named_parameters()}\n",
    "\n",
    "    losses, accs, eigs, traj_lengths = [], [], [], []\n",
    "\n",
    "    for epoch in range(1, iterations + 1):\n",
    "\n",
    "        for data, target in loader:\n",
    "\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "\n",
    "            if loss_fn == 'mse':\n",
    "                target_tensor = F.one_hot(target, num_classes=output.size(1)).float().to(device)\n",
    "            else:\n",
    "                target_tensor = target\n",
    "\n",
    "            loss = criterion(output, target_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        pred = output.argmax(dim = 1)\n",
    "        acc = pred.eq(target).sum().item() / len(target)\n",
    "        losses.append(loss.item())\n",
    "        accs.append(acc)\n",
    "        current_params = parameters_to_vector(model.parameters()).detach().clone().to(device)\n",
    "        step = current_params - prev_params\n",
    "        traj_lengths.append(step.norm().item())\n",
    "        prev_params = current_params\n",
    "\n",
    "\n",
    "        for name, param in model.named_parameters():\n",
    "            delta = param.detach() - prev_param_dict[name]\n",
    "            cumulative_changes[name] += delta.abs().norm().item()\n",
    "            prev_param_dict[name] = param.detach().clone()\n",
    "\n",
    "        if epoch % hessian_freq == 0:\n",
    "            hv_loader = DataLoader(subset, batch_size = len(subset), shuffle = False)\n",
    "            evals = lanczos(\n",
    "                lambda v: compute_hvp(model, criterion_sum, hv_loader, v),\n",
    "                dim = len(current_params),\n",
    "                neigs = hessian_k,\n",
    "                device = device\n",
    "            )\n",
    "            eigs.append(evals.cpu().tolist())\n",
    "        else:\n",
    "            eigs.append([None] * hessian_k)\n",
    "\n",
    "        print(f\"Iter {epoch}/{iterations} Loss: {loss.item():.4f} Acc: {acc:.4f} Eigs: {eigs[-1]}\")\n",
    "\n",
    "    generate_visuals(iterations, losses, accs, traj_lengths, eigs, cumulative_changes, learning_rate, hessian_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f53c2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduced_run_experiment(\n",
    "    subset_size: int,\n",
    "    seed_data: int,\n",
    "    seed_params: int,\n",
    "    hidden_sizes: List[int],\n",
    "    activation: str,\n",
    "    loss_fn: str,\n",
    "    learning_rate: float,\n",
    "    iterations: int,\n",
    "    hessian_freq: int,\n",
    "    hessian_k: int\n",
    "):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    \n",
    "    initial_state = torch.get_rng_state()\n",
    "    \n",
    "    torch.manual_seed(seed_data)\n",
    "    full_train = datasets.MNIST(root = './data', train = True, download = True, transform = transforms.ToTensor())\n",
    "    subset = Subset(full_train, torch.randperm(len(full_train))[:subset_size].tolist())\n",
    "    loader = DataLoader(subset, batch_size = len(subset), shuffle = False)\n",
    "    \n",
    "    torch.set_rng_state(initial_state)\n",
    "    torch.manual_seed(seed_params)\n",
    "    \n",
    "    model = FCNN(activation, hidden_sizes).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "    criterion = {'cross_entropy': nn.CrossEntropyLoss(), 'mse': nn.MSELoss()}[loss_fn]\n",
    "    criterion_sum = {'cross_entropy': nn.CrossEntropyLoss(reduction = 'sum'), 'mse': nn.MSELoss(reduction = 'sum')}[loss_fn]\n",
    "\n",
    "    params = parameters_to_vector(model.parameters())\n",
    "    \n",
    "    losses, accs, eigs = [], [], []\n",
    "\n",
    "    for epoch in range(1, iterations + 1):\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "\n",
    "            if loss_fn == 'mse':\n",
    "                target_tensor = F.one_hot(target, num_classes=output.size(1)).float().to(device)\n",
    "            else:\n",
    "                target_tensor = target\n",
    "\n",
    "            loss = criterion(output, target_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        pred = output.argmax(dim = 1)\n",
    "        acc = pred.eq(target).sum().item() / len(target)\n",
    "        losses.append(loss.item())\n",
    "        accs.append(acc)\n",
    "\n",
    "        if epoch % hessian_freq == 0:\n",
    "            hv_loader = DataLoader(subset, batch_size = len(subset), shuffle = False)\n",
    "            evals = lanczos(\n",
    "                lambda v: compute_hvp(model, criterion_sum, hv_loader, v),\n",
    "                dim = len(parameters_to_vector(model.parameters())),\n",
    "                neigs = hessian_k,\n",
    "                device = device\n",
    "            )\n",
    "            eigs.append(evals.cpu().tolist())\n",
    "        else:\n",
    "            eigs.append([None] * hessian_k)\n",
    "\n",
    "    print(f\"Final Loss: {losses[-1]:.4f} Final Acc: {accs[-1]:.4f} Eigs: {eigs[-1]}\")\n",
    "\n",
    "    return {\n",
    "        'losses': losses,\n",
    "        'accs': accs,\n",
    "        'eigs': eigs,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb1217f",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment(\n",
    "    subset_size = 5000,\n",
    "    seed_data = 1,\n",
    "    seed_params = 1,\n",
    "    hidden_sizes = [32, 32],\n",
    "    activation = 'relu',\n",
    "    loss_fn = 'mse',\n",
    "    learning_rate = 0.01,\n",
    "    iterations = 2000,\n",
    "    hessian_freq = 100,\n",
    "    hessian_k = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b777cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment(\n",
    "    subset_size = 5000,\n",
    "    seed_data = 1,\n",
    "    seed_params = 2,\n",
    "    hidden_sizes = [32, 32],\n",
    "    activation = 'relu',\n",
    "    loss_fn = 'mse',\n",
    "    learning_rate = 0.01,\n",
    "    iterations = 2000,\n",
    "    hessian_freq = 100,\n",
    "    hessian_k = 3\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
